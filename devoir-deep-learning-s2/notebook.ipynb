{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EwL5a2PtF0Tx"
   },
   "source": [
    "**Regression Linéaire**\n",
    "Cette premiére partie est consacrée à la création d'un modéle de regression linéaire pour prédire les effets des changements climatiques.\n",
    "Vous pourrez utiliser tous les documents de cours et bibliothéques nécessaires de python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EZJOI7ryF6gq"
   },
   "source": [
    "De nombreuses études ont démontré que la température mondiale moyenne a augmenté au cours du siècle dernier. Les conséquences d'une augmentation continue de la température mondiale seront désastreuses. L'élévation du niveau de la mer et une fréquence accrue d'événements météorologiques extrêmes toucheront des milliards de personnes.\n",
    "\n",
    "Dans ce problème, nous tenterons d'étudier la relation entre la température moyenne mondiale et plusieurs autres facteurs.\n",
    "\n",
    "Le fichier Climate_change (CSV) contient des données climatiques de mai 1983 à décembre 2008. Les variables disponibles incluent:\n",
    "\n",
    "**Année:** l'année d'observation.\n",
    "\n",
    "**Mois:** le mois d'observation.\n",
    "\n",
    "**Temp:** la différence en degrés Celsius entre la température globale moyenne pendant cette période et une valeur de référence. Ces données proviennent de l'Unité de recherche climatique de l'Université d'East Anglia.\n",
    "\n",
    "**CO2, N2O, CH4, CFC.11, CFC.12:** concentrations atmosphériques de dioxyde de carbone (CO2), d'oxyde nitreux (N2O), de méthane (CH4), de trichlorofluorométhane (CCl3F; communément appelé CFC-11) et de dichlorodifluorométhane (CCl2F2 ; communément appelé CFC-12), respectivement. Ces données proviennent de la Division de surveillance mondiale ESRL / NOAA.\n",
    "Le CO2, N2O et CH4 sont exprimés en ppmv (parties par million en volume - c'est-à-dire 397 ppmv de CO2 signifie que le CO2 constitue 397 millionièmes du volume total de l'atmosphère)\n",
    "Les CFC.11 et CFC.12 sont exprimés en ppbv (parties par milliard en volume).\n",
    "\n",
    "**Aérosols:**\n",
    "la profondeur optique moyenne des aérosols stratosphériques à 550 nm. Cette variable est liée aux volcans, car les éruptions volcaniques entraînent l'ajout de nouvelles particules à l'atmosphère, ce qui affecte la quantité d'énergie solaire réfléchie dans l'espace. Ces données proviennent du Godard Institute for Space Studies de la NASA.\n",
    "\n",
    "**TSI:** l'irradiance solaire totale (TSI) en W / m2 (le taux auquel l'énergie solaire est déposée par unité de surface). En raison des taches solaires et d'autres phénomènes solaires, la quantité d'énergie émise par le soleil varie considérablement avec le temps. Ces données proviennent du site web du projet SOLARIS-HEPPA.\n",
    "\n",
    "**MEI:** indice d'oscillation australe multivarié El Nino (MEI), une mesure de la force de l'oscillation australe El Nino / La Nina (un effet météorologique dans l'océan Pacifique qui affecte les températures mondiales). Ces données proviennent de la Division des Sciences Physiques ESRL / NOAA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WzyMkUBnH3yY"
   },
   "source": [
    "Nous nous intéressons à la manière dont les changements de ces variables affectent les températures futures, ainsi qu'à la façon dont ces variables expliquent les changements de température jusqu'à présent. Pour ce faire, lisez d'abord le jeu de données Climate_change.csv dans python avec pandas.\n",
    "\n",
    "Ensuite, divisez les données en un ensemble d'apprentissage, composé de toutes les observations jusqu'en 2006 inclusivement, et un ensemble de test comprenant les années restantes (indice: utiliser un sous-ensemble). Un ensemble d'apprentissage fait référence aux données qui seront utilisées pour construire le modèle (ce sont les données que nous donnons à la fonction lm ()), et un ensemble de test fait référence aux données que nous utiliserons pour tester notre capacité prédictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btVSLAH6IJ_G"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"path = '/content/drive/My Drive/Colab Notebooks/ml-coursera-python-assignments/Devoir1LinearRegLogisticReg'\\nimport sys\\nsys.path.append(path)\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''path = '/content/drive/My Drive/Colab Notebooks/ml-coursera-python-assignments/Devoir1LinearRegLogisticReg'\n",
    "import sys\n",
    "sys.path.append(path)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2IPtE9GItHp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from numpy.linalg import norm\n",
    "from scipy import optimize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jfYI5aSyNQPU"
   },
   "source": [
    "**Lecture du jeu de données avec pandas et affichage des 10 premiéres lignes**\n",
    "\n",
    "Nous nous intéressons à la manière dont les changements de ces variables affectent les températures futures, ainsi qu'à la façon dont ces variables expliquent les changements de température jusqu'à présent. Pour ce faire, lisez d'abord le jeu de données Climate_change.csv avec pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VzuCijx1MHZy"
   },
   "outputs": [],
   "source": [
    "climate_change = pd.read_csv('Data/climate_change.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "xiyIOSNQMaQo",
    "outputId": "8e1688c2-92dd-44f1-9406-9aeced14845b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>MEI</th>\n",
       "      <th>CO2</th>\n",
       "      <th>CH4</th>\n",
       "      <th>N2O</th>\n",
       "      <th>CFC-11</th>\n",
       "      <th>CFC-12</th>\n",
       "      <th>TSI</th>\n",
       "      <th>Aerosols</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1983</td>\n",
       "      <td>5</td>\n",
       "      <td>2.556</td>\n",
       "      <td>345.96</td>\n",
       "      <td>1638.59</td>\n",
       "      <td>303.677</td>\n",
       "      <td>191.324</td>\n",
       "      <td>350.113</td>\n",
       "      <td>1366.1024</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1983</td>\n",
       "      <td>6</td>\n",
       "      <td>2.167</td>\n",
       "      <td>345.52</td>\n",
       "      <td>1633.71</td>\n",
       "      <td>303.746</td>\n",
       "      <td>192.057</td>\n",
       "      <td>351.848</td>\n",
       "      <td>1366.1208</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1983</td>\n",
       "      <td>7</td>\n",
       "      <td>1.741</td>\n",
       "      <td>344.15</td>\n",
       "      <td>1633.22</td>\n",
       "      <td>303.795</td>\n",
       "      <td>192.818</td>\n",
       "      <td>353.725</td>\n",
       "      <td>1366.2850</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1983</td>\n",
       "      <td>8</td>\n",
       "      <td>1.130</td>\n",
       "      <td>342.25</td>\n",
       "      <td>1631.35</td>\n",
       "      <td>303.839</td>\n",
       "      <td>193.602</td>\n",
       "      <td>355.633</td>\n",
       "      <td>1366.4202</td>\n",
       "      <td>0.0673</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1983</td>\n",
       "      <td>9</td>\n",
       "      <td>0.428</td>\n",
       "      <td>340.17</td>\n",
       "      <td>1648.40</td>\n",
       "      <td>303.901</td>\n",
       "      <td>194.392</td>\n",
       "      <td>357.465</td>\n",
       "      <td>1366.2335</td>\n",
       "      <td>0.0619</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1983</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002</td>\n",
       "      <td>340.30</td>\n",
       "      <td>1663.79</td>\n",
       "      <td>303.970</td>\n",
       "      <td>195.171</td>\n",
       "      <td>359.174</td>\n",
       "      <td>1366.0589</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1983</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>341.53</td>\n",
       "      <td>1658.23</td>\n",
       "      <td>304.032</td>\n",
       "      <td>195.921</td>\n",
       "      <td>360.758</td>\n",
       "      <td>1366.1072</td>\n",
       "      <td>0.0524</td>\n",
       "      <td>0.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1983</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>343.07</td>\n",
       "      <td>1654.31</td>\n",
       "      <td>304.082</td>\n",
       "      <td>196.609</td>\n",
       "      <td>362.174</td>\n",
       "      <td>1366.0607</td>\n",
       "      <td>0.0486</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1984</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>344.05</td>\n",
       "      <td>1658.98</td>\n",
       "      <td>304.130</td>\n",
       "      <td>197.219</td>\n",
       "      <td>363.359</td>\n",
       "      <td>1365.4261</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1984</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>344.77</td>\n",
       "      <td>1656.48</td>\n",
       "      <td>304.194</td>\n",
       "      <td>197.759</td>\n",
       "      <td>364.296</td>\n",
       "      <td>1365.6618</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month    MEI     CO2      CH4      N2O   CFC-11   CFC-12        TSI  \\\n",
       "0  1983      5  2.556  345.96  1638.59  303.677  191.324  350.113  1366.1024   \n",
       "1  1983      6  2.167  345.52  1633.71  303.746  192.057  351.848  1366.1208   \n",
       "2  1983      7  1.741  344.15  1633.22  303.795  192.818  353.725  1366.2850   \n",
       "3  1983      8  1.130  342.25  1631.35  303.839  193.602  355.633  1366.4202   \n",
       "4  1983      9  0.428  340.17  1648.40  303.901  194.392  357.465  1366.2335   \n",
       "5  1983     10  0.002  340.30  1663.79  303.970  195.171  359.174  1366.0589   \n",
       "6  1983     11 -0.176  341.53  1658.23  304.032  195.921  360.758  1366.1072   \n",
       "7  1983     12 -0.176  343.07  1654.31  304.082  196.609  362.174  1366.0607   \n",
       "8  1984      1 -0.339  344.05  1658.98  304.130  197.219  363.359  1365.4261   \n",
       "9  1984      2 -0.565  344.77  1656.48  304.194  197.759  364.296  1365.6618   \n",
       "\n",
       "   Aerosols   Temp  \n",
       "0    0.0863  0.109  \n",
       "1    0.0794  0.118  \n",
       "2    0.0731  0.137  \n",
       "3    0.0673  0.176  \n",
       "4    0.0619  0.149  \n",
       "5    0.0569  0.093  \n",
       "6    0.0524  0.232  \n",
       "7    0.0486  0.078  \n",
       "8    0.0451  0.089  \n",
       "9    0.0416  0.013  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_change.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "twkFUuBXzphL"
   },
   "source": [
    "**Quelles sont vos remarques par rapport à ces données?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarques** : Nous remarquons que ces données n'ont pas les mêmes ordres de grandeurs. Elles n'ont donc pas les mêmes unités de mesure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQAcIXu6Mp0S"
   },
   "source": [
    "**Valeurs manquantes:**\n",
    "\n",
    "Rechercher les valeurs manquantes et supprimer les lignes où elles se trouvent s'il y en a. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "EbnPv1i7M51B",
    "outputId": "357d99b6-f15f-4296-8270-ff3046687d6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year        0.0\n",
       "Month       0.0\n",
       "MEI         0.0\n",
       "CO2         0.0\n",
       "CH4         0.0\n",
       "N2O         0.0\n",
       "CFC-11      0.0\n",
       "CFC-12      0.0\n",
       "TSI         0.0\n",
       "Aerosols    0.0\n",
       "Temp        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valeurs manquantes\n",
    "\n",
    "total_missing = climate_change.isna().sum()\n",
    "\n",
    "percent_missing = total_missing / climate_change.count()\n",
    "\n",
    "percent_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfRQak3e49Bu"
   },
   "source": [
    "**Colonnes Year, Month et y**\n",
    "Enlever les colonnes sur Year et Month et mettre la colonne Temp dans une variable y qui representera les températures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gRAQVRuY7i2T"
   },
   "outputs": [],
   "source": [
    "climate_change_ini = climate_change.copy()\n",
    "climate_change = climate_change.drop(['Year','Month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XqxFXCs4-3y9"
   },
   "outputs": [],
   "source": [
    "y = climate_change['Temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_change = climate_change.drop(['Temp'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CjHGII9GUD_j"
   },
   "source": [
    "**Standardisation des données:**\n",
    "\n",
    "Les données ne sont pas à la même échelle. Il est important de les standardiser. Pour cela vous allez utiliser la bibliothéque scikit-learn(https://scikit-learn.org/stable/). \n",
    "\n",
    "StandardScaler permet de tout standardiser et de transformer les colonnes du Dataframe. Il est important de noter que StandardScaler retourne un numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YzyKBiCPXhXW"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "climate_change[climate_change.columns] = pd.DataFrame(scaler.fit_transform(climate_change))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "75dXPrjFX2vb"
   },
   "source": [
    "**Description du nouveau dataframe**\n",
    "\n",
    "Decrivez le nouveau dataframe avec la fonction describe() de pandans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "3mRGtjT8YERX",
    "outputId": "3efc1a2a-3677-4a56-e214-57a4850d0d90"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEI</th>\n",
       "      <th>CO2</th>\n",
       "      <th>CH4</th>\n",
       "      <th>N2O</th>\n",
       "      <th>CFC-11</th>\n",
       "      <th>CFC-12</th>\n",
       "      <th>TSI</th>\n",
       "      <th>Aerosols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.435346</td>\n",
       "      <td>-1.367493</td>\n",
       "      <td>-2.419359</td>\n",
       "      <td>-1.670583</td>\n",
       "      <td>-3.002591</td>\n",
       "      <td>-2.553339</td>\n",
       "      <td>0.079308</td>\n",
       "      <td>2.401281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.019923</td>\n",
       "      <td>-1.402340</td>\n",
       "      <td>-2.525499</td>\n",
       "      <td>-1.657356</td>\n",
       "      <td>-2.966302</td>\n",
       "      <td>-2.523287</td>\n",
       "      <td>0.125428</td>\n",
       "      <td>2.163370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.564986</td>\n",
       "      <td>-1.510841</td>\n",
       "      <td>-2.536157</td>\n",
       "      <td>-1.647963</td>\n",
       "      <td>-2.928626</td>\n",
       "      <td>-2.490775</td>\n",
       "      <td>0.536998</td>\n",
       "      <td>1.946146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.912484</td>\n",
       "      <td>-1.661317</td>\n",
       "      <td>-2.576829</td>\n",
       "      <td>-1.639529</td>\n",
       "      <td>-2.889812</td>\n",
       "      <td>-2.457726</td>\n",
       "      <td>0.875879</td>\n",
       "      <td>1.746163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.162800</td>\n",
       "      <td>-1.826049</td>\n",
       "      <td>-2.205991</td>\n",
       "      <td>-1.627644</td>\n",
       "      <td>-2.850701</td>\n",
       "      <td>-2.425994</td>\n",
       "      <td>0.407913</td>\n",
       "      <td>1.559971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>-0.578341</td>\n",
       "      <td>1.657080</td>\n",
       "      <td>0.653709</td>\n",
       "      <td>1.727772</td>\n",
       "      <td>-0.384826</td>\n",
       "      <td>0.650360</td>\n",
       "      <td>-1.037093</td>\n",
       "      <td>-0.450209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>-0.980949</td>\n",
       "      <td>1.573130</td>\n",
       "      <td>0.984310</td>\n",
       "      <td>1.751542</td>\n",
       "      <td>-0.390618</td>\n",
       "      <td>0.649945</td>\n",
       "      <td>-1.017793</td>\n",
       "      <td>-0.426074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>-1.127255</td>\n",
       "      <td>1.565210</td>\n",
       "      <td>1.399737</td>\n",
       "      <td>1.802724</td>\n",
       "      <td>-0.390767</td>\n",
       "      <td>0.647849</td>\n",
       "      <td>-0.989720</td>\n",
       "      <td>-0.415730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>-0.957454</td>\n",
       "      <td>1.655496</td>\n",
       "      <td>1.360369</td>\n",
       "      <td>1.844322</td>\n",
       "      <td>-0.383588</td>\n",
       "      <td>0.647485</td>\n",
       "      <td>-0.913021</td>\n",
       "      <td>-0.408834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>-1.005511</td>\n",
       "      <td>1.768749</td>\n",
       "      <td>1.371461</td>\n",
       "      <td>1.876718</td>\n",
       "      <td>-0.384628</td>\n",
       "      <td>0.649200</td>\n",
       "      <td>-0.947861</td>\n",
       "      <td>-0.415730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          MEI       CO2       CH4       N2O    CFC-11    CFC-12       TSI  \\\n",
       "0    2.435346 -1.367493 -2.419359 -1.670583 -3.002591 -2.553339  0.079308   \n",
       "1    2.019923 -1.402340 -2.525499 -1.657356 -2.966302 -2.523287  0.125428   \n",
       "2    1.564986 -1.510841 -2.536157 -1.647963 -2.928626 -2.490775  0.536998   \n",
       "3    0.912484 -1.661317 -2.576829 -1.639529 -2.889812 -2.457726  0.875879   \n",
       "4    0.162800 -1.826049 -2.205991 -1.627644 -2.850701 -2.425994  0.407913   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "303 -0.578341  1.657080  0.653709  1.727772 -0.384826  0.650360 -1.037093   \n",
       "304 -0.980949  1.573130  0.984310  1.751542 -0.390618  0.649945 -1.017793   \n",
       "305 -1.127255  1.565210  1.399737  1.802724 -0.390767  0.647849 -0.989720   \n",
       "306 -0.957454  1.655496  1.360369  1.844322 -0.383588  0.647485 -0.913021   \n",
       "307 -1.005511  1.768749  1.371461  1.876718 -0.384628  0.649200 -0.947861   \n",
       "\n",
       "     Aerosols  \n",
       "0    2.401281  \n",
       "1    2.163370  \n",
       "2    1.946146  \n",
       "3    1.746163  \n",
       "4    1.559971  \n",
       "..        ...  \n",
       "303 -0.450209  \n",
       "304 -0.426074  \n",
       "305 -0.415730  \n",
       "306 -0.408834  \n",
       "307 -0.415730  \n",
       "\n",
       "[308 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Izo5Df4YOkOZ"
   },
   "source": [
    "**Creation des ensembles d'apprentissage, de validation et de test**\n",
    "\n",
    "Vous utiliserez la bibliothéque scikit-learn pour determiner les ensembles d'apprentissage( 80%),  et de test(20%). La fonction train_test_split() (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html ) de sklean.model_selection permet de creer proprement les ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NVpSG-SyPXoZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(climate_change, y, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEI</th>\n",
       "      <th>CO2</th>\n",
       "      <th>CH4</th>\n",
       "      <th>N2O</th>\n",
       "      <th>CFC-11</th>\n",
       "      <th>CFC-12</th>\n",
       "      <th>TSI</th>\n",
       "      <th>Aerosols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>-0.942503</td>\n",
       "      <td>0.736799</td>\n",
       "      <td>1.124163</td>\n",
       "      <td>0.722911</td>\n",
       "      <td>0.477201</td>\n",
       "      <td>0.775956</td>\n",
       "      <td>0.855576</td>\n",
       "      <td>-0.501929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.262117</td>\n",
       "      <td>-0.122500</td>\n",
       "      <td>0.113437</td>\n",
       "      <td>-0.428405</td>\n",
       "      <td>0.926680</td>\n",
       "      <td>0.311749</td>\n",
       "      <td>-0.770400</td>\n",
       "      <td>0.132501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-0.036902</td>\n",
       "      <td>-0.921608</td>\n",
       "      <td>-0.281109</td>\n",
       "      <td>-0.673390</td>\n",
       "      <td>0.576414</td>\n",
       "      <td>-0.193837</td>\n",
       "      <td>1.363396</td>\n",
       "      <td>-0.374354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>-1.134730</td>\n",
       "      <td>0.287746</td>\n",
       "      <td>0.416851</td>\n",
       "      <td>0.415433</td>\n",
       "      <td>0.604435</td>\n",
       "      <td>0.723785</td>\n",
       "      <td>1.008724</td>\n",
       "      <td>-0.501929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1.074926</td>\n",
       "      <td>-1.133067</td>\n",
       "      <td>-1.805137</td>\n",
       "      <td>-1.408346</td>\n",
       "      <td>-1.987734</td>\n",
       "      <td>-2.043647</td>\n",
       "      <td>-1.088226</td>\n",
       "      <td>-0.132994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-1.193466</td>\n",
       "      <td>-0.604816</td>\n",
       "      <td>-0.559945</td>\n",
       "      <td>-0.906682</td>\n",
       "      <td>0.081684</td>\n",
       "      <td>-0.598701</td>\n",
       "      <td>1.301986</td>\n",
       "      <td>-0.367458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.376385</td>\n",
       "      <td>1.516899</td>\n",
       "      <td>0.350731</td>\n",
       "      <td>1.433904</td>\n",
       "      <td>-0.134961</td>\n",
       "      <td>0.730956</td>\n",
       "      <td>-0.625524</td>\n",
       "      <td>-0.443313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>-0.024087</td>\n",
       "      <td>0.660769</td>\n",
       "      <td>0.434468</td>\n",
       "      <td>0.722144</td>\n",
       "      <td>0.427693</td>\n",
       "      <td>0.771955</td>\n",
       "      <td>1.628084</td>\n",
       "      <td>-0.501929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>-0.291069</td>\n",
       "      <td>0.629881</td>\n",
       "      <td>1.016935</td>\n",
       "      <td>0.860930</td>\n",
       "      <td>0.418782</td>\n",
       "      <td>0.794940</td>\n",
       "      <td>2.055946</td>\n",
       "      <td>-0.498481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>-0.919009</td>\n",
       "      <td>1.322072</td>\n",
       "      <td>1.067178</td>\n",
       "      <td>1.398633</td>\n",
       "      <td>-0.048719</td>\n",
       "      <td>0.766880</td>\n",
       "      <td>-0.541054</td>\n",
       "      <td>-0.450209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          MEI       CO2       CH4       N2O    CFC-11    CFC-12       TSI  \\\n",
       "214 -0.942503  0.736799  1.124163  0.722911  0.477201  0.775956  0.855576   \n",
       "132  0.262117 -0.122500  0.113437 -0.428405  0.926680  0.311749 -0.770400   \n",
       "89  -0.036902 -0.921608 -0.281109 -0.673390  0.576414 -0.193837  1.363396   \n",
       "195 -1.134730  0.287746  0.416851  0.415433  0.604435  0.723785  1.008724   \n",
       "24  -1.074926 -1.133067 -1.805137 -1.408346 -1.987734 -2.043647 -1.088226   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "71  -1.193466 -0.604816 -0.559945 -0.906682  0.081684 -0.598701  1.301986   \n",
       "278  0.376385  1.516899  0.350731  1.433904 -0.134961  0.730956 -0.625524   \n",
       "218 -0.024087  0.660769  0.434468  0.722144  0.427693  0.771955  1.628084   \n",
       "223 -0.291069  0.629881  1.016935  0.860930  0.418782  0.794940  2.055946   \n",
       "271 -0.919009  1.322072  1.067178  1.398633 -0.048719  0.766880 -0.541054   \n",
       "\n",
       "     Aerosols  \n",
       "214 -0.501929  \n",
       "132  0.132501  \n",
       "89  -0.374354  \n",
       "195 -0.501929  \n",
       "24  -0.132994  \n",
       "..        ...  \n",
       "71  -0.367458  \n",
       "278 -0.443313  \n",
       "218 -0.501929  \n",
       "223 -0.498481  \n",
       "271 -0.450209  \n",
       "\n",
       "[246 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmXykzzi52PV"
   },
   "source": [
    "**Creation du modele de regression linéaire**\n",
    "\n",
    "Vous allez implementer les algorithmes du gradient descent et du calcul de la fonction cout regularisée avec la norme L2. Vous ecrirez deux versions de cette fonction: batch gradient descent et stochastic gradient descent. La fonction de calcul du cost function regularisée est deja implémentée pour vous.  Vous pouvez vous reférer au cours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yMuSj2N16M84"
   },
   "outputs": [],
   "source": [
    "# Fonction coût\n",
    "def linearRegCostFunction(X, y, theta, lambda_=0.0):\n",
    "    \"\"\"\n",
    "    Compute cost and gradient for regularized linear regression \n",
    "    with multiple variables. Computes the cost of using theta as\n",
    "    the parameter for linear regression to fit the data points in X and y. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The dataset. Matrix with shape (m x n + 1) where m is the \n",
    "        total number of examples, and n is the number of features \n",
    "        before adding the bias term.\n",
    "    \n",
    "    y : array_like\n",
    "        The functions values at each datapoint. A vector of\n",
    "        shape (m, ).\n",
    "    \n",
    "    theta : array_like\n",
    "        The parameters for linear regression. A vector of shape (n+1,).\n",
    "    \n",
    "    lambda_ : float, optional\n",
    "        The regularization parameter.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    J : float\n",
    "        The computed cost function. \n",
    "    \n",
    "    grad : array_like\n",
    "        The value of the cost function gradient w.r.t theta. \n",
    "        A vector of shape (n+1, ).\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Compute the cost and gradient of regularized linear regression for\n",
    "    a particular choice of theta.\n",
    "    You should set J to the cost and grad to the gradient.\n",
    "    \"\"\"\n",
    "    # Initialize some useful values\n",
    "    m = y.size # number of training examples\n",
    "\n",
    "    # You need to return the following variables correctly \n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "    \n",
    "    I = np.ones(theta.shape)\n",
    "    I[:1]= 0.0\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    \n",
    "    #  Utliser le broadcasting entre theta et X, sommer ce vecteur suivant l'axe des colonnes et enlever y\n",
    "    # TODO\n",
    "    modele = np.array(np.sum(X*theta, axis=1)).T\n",
    "    J = ( 1. / (2*m) ) * (((modele - y)**2).sum() + (lambda_ / 2)*(norm(theta,2)**2))\n",
    "    grad = (1. / m) * X.T.dot(modele - y) + (lambda_ / m)*theta\n",
    "    \n",
    "    # ============================================================\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49.63, array([9.9, 9.9, 9.9, 9.9]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vérification\n",
    "linearRegCostFunction(np.ones((4,4)), np.array([1,2,3,4]), np.array([0.5,1.9,2, 8]), lambda_=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SCgL-hcs_B6-"
   },
   "source": [
    "Une fois que votre fonction de coût et votre gradient fonctionnent correctement, la cellule suivante exécutera le code dans trainLinearReg  pour calculer les valeurs optimales de 𝜃. Cette fonction de formation utilise le module d'optimisation de scipy pour minimiser la fonction de coût.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHcgxk1d7P3c"
   },
   "outputs": [],
   "source": [
    "# Gradient Descent\n",
    "def trainLinearReg(linearRegCostFunction, X, y, lambda_=0.0, maxiter=200):\n",
    "    \"\"\"\n",
    "    Trains linear regression using scipy's optimize.minimize.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The dataset with shape (m x n+1). The bias term is assumed to be concatenated.\n",
    "\n",
    "    y : array_like\n",
    "        Function values at each datapoint. A vector of shape (m,).\n",
    "\n",
    "    lambda_ : float, optional\n",
    "        The regularization parameter.\n",
    "\n",
    "    maxiter : int, optional\n",
    "        Maximum number of iteration for the optimization algorithm.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    theta : array_like\n",
    "        The parameters for linear regression. This is a vector of shape (n+1,).\n",
    "    \"\"\"\n",
    "    # Initialize Theta\n",
    "    initial_theta = np.zeros(X.shape[1])\n",
    "\n",
    "    # Create \"short hand\" for the cost function to be minimized\n",
    "    costFunction = lambda t: linearRegCostFunction(X, y, t, lambda_)\n",
    "\n",
    "    # Now, costFunction is a function that takes in only one argument\n",
    "    options = {'maxiter': maxiter}\n",
    "\n",
    "    # Minimize using scipy\n",
    "    res = optimize.minimize(costFunction, initial_theta, jac=True, method='TNC', options=options)\n",
    "    return res.x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hfQdIwO6-r84"
   },
   "source": [
    "**Execution de la fonction de gradient descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1NC8kl7A-xpV"
   },
   "outputs": [],
   "source": [
    "# On recupére les données dans un tableau numpy\n",
    "# On ajoute une collone de 1 pour le bias\n",
    "\n",
    "X_train_aug = np.concatenate([np.ones((X_train.shape[0], 1)), X_train], axis=1)\n",
    "theta = trainLinearReg(linearRegCostFunction, X_train_aug, y_train, lambda_=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38VDmPQ8BqDL"
   },
   "source": [
    "**Visualiser les valeur de theta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Q2Je13_cB_Lo",
    "outputId": "3037cba2-76ba-4cc7-d21e-56300efc4c61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25338899  0.06529388  0.07400292  0.02332865 -0.09236735 -0.13881049\n",
      "  0.21841578  0.03991129 -0.03981616]\n"
     ]
    }
   ],
   "source": [
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3GpPkm1IREJY"
   },
   "source": [
    "**Validation du modéle: courbe d'apprentissage**\n",
    "\n",
    "Vous allez maintenant implémenter du code pour générer les courbes d'apprentissage qui seront utiles dans le débogage des algorithmes d'apprentissage. Rappelez-vous qu'une courbe d'apprentissage trace les erreurs d'entraînement et de validation croisée en fonction de la taille de l'ensemble d'apprentissage. Votre travail consiste à remplir la fonction learningCurve dans la cellule suivante, de sorte qu'elle renvoie un vecteur d'erreurs pour l'ensemble d'apprentissage et l'ensemble de validation croisée.\n",
    "\n",
    "Pour tracer la courbe d'apprentissage, nous avons besoin d'une erreur d'ensemble d'entraînement et de validation croisée pour différentes tailles d'ensemble d'entraînement. Pour obtenir différentes tailles d'ensemble d'apprentissage, vous devez utiliser différents sous-ensembles de l'ensemble d'entraînement d'origine X. Plus précisément, pour une taille d'ensemble d'apprentissage de 𝑖, vous devez utiliser les premiers exemples 𝑖 (c'est-à-dire, X [: i,:] et y [: je]).\n",
    "\n",
    "Vous pouvez utiliser la fonction trainLinearReg (en appelant utils.trainLinearReg (...)) pour trouver les paramètres 𝜃. Notez que lambda_ est passé en paramètre à la fonction learningCurve. Après avoir appris les paramètres 𝜃, vous devez calculer l'erreur sur les ensembles d'apprentissage et de validation croisée. Rappelez-vous que l'erreur d'apprentissage pour un ensemble de données est définie comme:\n",
    "\n",
    "$$ J_{\\text{train}} = \\frac{1}{2m} \\left[ \\sum_{i=1}^m \\left(h_\\theta \\left( x^{(i)} \\right) - y^{(i)} \\right)^2 \\right] $$\n",
    "\n",
    "En particulier, notez que l'erreur d'entrainement n'inclut pas le terme de régularisation. Une façon de calculer l'erreur d'entraînement consiste à utiliser votre fonction de coût existante et à définir $ \\ lambda $ sur 0 uniquement lorsque vous l'utilisez pour calculer l'erreur d'entraînement et l'erreur de validation croisée. Lorsque vous calculez l'erreur d'ensemble d'apprentissage, assurez-vous de la calculer sur le sous-ensemble d'apprentissage (c'est-à-dire, `X [: n,:]` et `y [: n]`) au lieu de l'ensemble d'apprentissage entier. Cependant, pour l'erreur de validation croisée, vous devez la calculer sur  l'ensemble de validation croisée qui est votre ensemble de test dans le cadre de cet exercice. Vous devriez stocker\n",
    "les erreurs calculées dans deux vecteurs: un pour  le train et un autre pour la validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "grwluDoeDowF"
   },
   "outputs": [],
   "source": [
    "def learningCurve(X, y, Xval, yval, lambda_=0):\n",
    "    \"\"\"\n",
    "    Generates the train and cross validation set errors needed to plot a learning curve\n",
    "    returns the train and cross validation set errors for a learning curve. \n",
    "    \n",
    "    In this function, you will compute the train and test errors for\n",
    "    dataset sizes from 1 up to m. In practice, when working with larger\n",
    "    datasets, you might want to do this in larger intervals.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The training dataset. Matrix with shape (m x n + 1) where m is the \n",
    "        total number of examples, and n is the number of features \n",
    "        before adding the bias term.\n",
    "    \n",
    "    y : array_like\n",
    "        The functions values at each training datapoint. A vector of\n",
    "        shape (m, ).\n",
    "    \n",
    "    Xval : array_like\n",
    "        The validation dataset. Matrix with shape (m_val x n + 1) where m is the \n",
    "        total number of examples, and n is the number of features \n",
    "        before adding the bias term.\n",
    "    \n",
    "    yval : array_like\n",
    "        The functions values at each validation datapoint. A vector of\n",
    "        shape (m_val, ).\n",
    "    \n",
    "    lambda_ : float, optional\n",
    "        The regularization parameter.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    error_train : array_like\n",
    "        A vector of shape m. error_train[i] contains the training error for\n",
    "        i examples.\n",
    "    error_val : array_like\n",
    "        A vecotr of shape m. error_val[i] contains the validation error for\n",
    "        i training examples.\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Fill in this function to return training errors in error_train and the\n",
    "    cross validation errors in error_val. i.e., error_train[i] and \n",
    "    error_val[i] should give you the errors obtained after training on i examples.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - You should evaluate the training error on the first i training\n",
    "      examples (i.e., X[:i, :] and y[:i]).\n",
    "    \n",
    "      For the cross-validation error, you should instead evaluate on\n",
    "      the _entire_ cross validation set (Xval and yval).\n",
    "    \n",
    "    - If you are using your cost function (linearRegCostFunction) to compute\n",
    "      the training and cross validation error, you should call the function with\n",
    "      the lambda argument set to 0. Do note that you will still need to use\n",
    "      lambda when running the training to obtain the theta parameters.\n",
    "    \n",
    "    Hint\n",
    "    ----\n",
    "    You can loop over the examples with the following:\n",
    "     \n",
    "           for i in range(1, m+1):\n",
    "               # Compute train/cross validation errors using training examples \n",
    "               # X[:i, :] and y[:i], storing the result in \n",
    "               # error_train[i-1] and error_val[i-1]\n",
    "               ....  \n",
    "    \"\"\"\n",
    "    # Number of training examples\n",
    "    m = y.size\n",
    "\n",
    "    # You need to return these values correctly\n",
    "    error_train = np.zeros(m)\n",
    "    error_val   = np.zeros(m)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    for i in range(1, m+1):\n",
    "      # Compute train/cross validation errors using training examples \n",
    "      # X[:i, :] and y[:i], storing the result in\n",
    "      theta = trainLinearReg(linearRegCostFunction, X[:i, :], y[:i], lambda_=0)\n",
    "\n",
    "      error_train[i-1] , _ = linearRegCostFunction(X[:i, :], y[:i], theta, 0.0)\n",
    "\n",
    "      error_val[i-1] , _ = linearRegCostFunction(Xval[:i, :], yval[:i], theta, 0.0)\n",
    "\n",
    "      \n",
    "        \n",
    "    # =============================================================\n",
    "    return error_train, error_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6SnLVuD2TRl7"
   },
   "outputs": [],
   "source": [
    "X_test_aug = np.concatenate([np.ones((X_test.shape[0], 1)), X_test], axis=1)\n",
    "error_train,error_test = learningCurve(X_train_aug, y_train, X_test_aug, y_test, lambda_=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p7HBsez-UBPy"
   },
   "source": [
    "**Visualiser la courbe d'apprentissage**\n",
    "\n",
    "Utiliser seaborn ou matplotlib pour visualiser le learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "85KNDvuYUMgS",
    "outputId": "14845d02-0d1d-4830-ef3d-f47e13d56693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Training Examples\tTrain Error\tCross Validation Error\n",
      "  \t1\t\t0.000000\t0.003773\n",
      "  \t2\t\t0.000000\t0.007200\n",
      "  \t3\t\t0.000000\t0.000936\n",
      "  \t4\t\t0.000000\t0.006464\n",
      "  \t5\t\t0.000000\t0.012105\n",
      "  \t6\t\t0.000000\t0.003728\n",
      "  \t7\t\t0.000000\t0.005760\n",
      "  \t8\t\t0.000000\t0.227223\n",
      "  \t9\t\t0.000000\t0.191077\n",
      "  \t10\t\t0.000025\t0.173036\n",
      "  \t11\t\t0.000600\t0.004108\n",
      "  \t12\t\t0.000550\t0.003737\n",
      "  \t13\t\t0.000578\t0.011449\n",
      "  \t14\t\t0.000553\t0.008799\n",
      "  \t15\t\t0.000517\t0.008243\n",
      "  \t16\t\t0.000633\t0.006768\n",
      "  \t17\t\t0.000812\t0.002518\n",
      "  \t18\t\t0.000791\t0.002784\n",
      "  \t19\t\t0.000759\t0.002614\n",
      "  \t20\t\t0.000742\t0.002729\n",
      "  \t21\t\t0.000707\t0.002663\n",
      "  \t22\t\t0.000677\t0.005498\n",
      "  \t23\t\t0.000702\t0.004950\n",
      "  \t24\t\t0.000751\t0.008109\n",
      "  \t25\t\t0.000873\t0.007970\n",
      "  \t26\t\t0.000841\t0.007928\n",
      "  \t27\t\t0.001211\t0.008360\n",
      "  \t28\t\t0.001299\t0.007526\n",
      "  \t29\t\t0.001257\t0.009240\n",
      "  \t30\t\t0.001215\t0.008954\n",
      "  \t31\t\t0.001178\t0.008588\n",
      "  \t32\t\t0.001316\t0.009813\n",
      "  \t33\t\t0.001353\t0.009279\n",
      "  \t34\t\t0.001391\t0.008700\n",
      "  \t35\t\t0.002256\t0.008501\n",
      "  \t36\t\t0.002254\t0.010525\n",
      "  \t37\t\t0.002452\t0.010193\n",
      "  \t38\t\t0.002416\t0.010127\n",
      "  \t39\t\t0.002356\t0.010275\n",
      "  \t40\t\t0.002438\t0.009880\n",
      "  \t41\t\t0.002418\t0.009626\n",
      "  \t42\t\t0.002447\t0.008789\n",
      "  \t43\t\t0.002390\t0.008582\n",
      "  \t44\t\t0.002534\t0.008720\n",
      "  \t45\t\t0.002477\t0.008613\n",
      "  \t46\t\t0.002463\t0.008578\n",
      "  \t47\t\t0.002430\t0.008378\n",
      "  \t48\t\t0.002411\t0.008373\n",
      "  \t49\t\t0.002497\t0.008479\n",
      "  \t50\t\t0.002536\t0.008534\n",
      "  \t51\t\t0.002896\t0.009912\n",
      "  \t52\t\t0.002868\t0.009875\n",
      "  \t53\t\t0.002893\t0.009200\n",
      "  \t54\t\t0.003082\t0.008899\n",
      "  \t55\t\t0.003032\t0.008651\n",
      "  \t56\t\t0.003075\t0.007705\n",
      "  \t57\t\t0.003409\t0.006903\n",
      "  \t58\t\t0.003403\t0.006776\n",
      "  \t59\t\t0.003406\t0.006632\n",
      "  \t60\t\t0.003397\t0.006491\n",
      "  \t61\t\t0.003435\t0.006468\n",
      "  \t62\t\t0.003419\t0.006381\n",
      "  \t63\t\t0.003380\t0.006405\n",
      "  \t64\t\t0.003386\t0.006324\n",
      "  \t65\t\t0.003451\t0.006274\n",
      "  \t66\t\t0.003402\t0.006277\n",
      "  \t67\t\t0.003430\t0.006240\n",
      "  \t68\t\t0.003381\t0.006234\n",
      "  \t69\t\t0.003360\t0.006221\n",
      "  \t70\t\t0.003314\t0.006213\n",
      "  \t71\t\t0.003270\t0.006224\n",
      "  \t72\t\t0.003399\t0.006160\n",
      "  \t73\t\t0.003397\t0.006087\n",
      "  \t74\t\t0.003766\t0.006090\n",
      "  \t75\t\t0.003722\t0.006070\n",
      "  \t76\t\t0.003690\t0.006069\n",
      "  \t77\t\t0.003647\t0.006032\n",
      "  \t78\t\t0.003742\t0.005973\n",
      "  \t79\t\t0.003747\t0.005940\n",
      "  \t80\t\t0.003792\t0.005822\n",
      "  \t81\t\t0.003786\t0.005822\n",
      "  \t82\t\t0.003764\t0.005835\n",
      "  \t83\t\t0.003748\t0.005893\n",
      "  \t84\t\t0.003706\t0.005898\n",
      "  \t85\t\t0.003662\t0.005896\n",
      "  \t86\t\t0.003685\t0.005888\n",
      "  \t87\t\t0.003719\t0.005893\n",
      "  \t88\t\t0.003681\t0.005923\n",
      "  \t89\t\t0.003643\t0.005947\n",
      "  \t90\t\t0.003630\t0.005900\n",
      "  \t91\t\t0.003599\t0.005871\n",
      "  \t92\t\t0.003559\t0.005866\n",
      "  \t93\t\t0.003535\t0.005867\n",
      "  \t94\t\t0.003513\t0.005889\n",
      "  \t95\t\t0.003478\t0.005908\n",
      "  \t96\t\t0.003453\t0.005909\n",
      "  \t97\t\t0.003420\t0.005917\n",
      "  \t98\t\t0.003386\t0.005916\n",
      "  \t99\t\t0.003354\t0.005934\n",
      "  \t100\t\t0.003412\t0.006014\n",
      "  \t101\t\t0.003391\t0.005965\n",
      "  \t102\t\t0.003366\t0.005962\n",
      "  \t103\t\t0.003334\t0.005974\n",
      "  \t104\t\t0.003310\t0.005962\n",
      "  \t105\t\t0.003323\t0.005926\n",
      "  \t106\t\t0.003356\t0.005961\n",
      "  \t107\t\t0.003376\t0.005997\n",
      "  \t108\t\t0.003423\t0.006024\n",
      "  \t109\t\t0.003622\t0.005966\n",
      "  \t110\t\t0.003589\t0.005966\n",
      "  \t111\t\t0.003568\t0.005953\n",
      "  \t112\t\t0.003600\t0.005875\n",
      "  \t113\t\t0.003596\t0.005918\n",
      "  \t114\t\t0.003566\t0.005920\n",
      "  \t115\t\t0.003545\t0.005958\n",
      "  \t116\t\t0.003573\t0.006023\n",
      "  \t117\t\t0.003544\t0.006034\n",
      "  \t118\t\t0.003514\t0.006030\n",
      "  \t119\t\t0.003514\t0.006010\n",
      "  \t120\t\t0.003493\t0.006029\n",
      "  \t121\t\t0.003466\t0.006023\n",
      "  \t122\t\t0.003447\t0.006014\n",
      "  \t123\t\t0.003440\t0.005971\n",
      "  \t124\t\t0.003433\t0.005984\n",
      "  \t125\t\t0.003408\t0.005981\n",
      "  \t126\t\t0.003383\t0.005971\n",
      "  \t127\t\t0.003357\t0.005975\n",
      "  \t128\t\t0.003332\t0.005976\n",
      "  \t129\t\t0.003322\t0.005986\n",
      "  \t130\t\t0.003311\t0.005956\n",
      "  \t131\t\t0.003309\t0.005964\n",
      "  \t132\t\t0.003305\t0.005965\n",
      "  \t133\t\t0.003295\t0.005954\n",
      "  \t134\t\t0.003347\t0.005965\n",
      "  \t135\t\t0.003334\t0.005996\n",
      "  \t136\t\t0.003487\t0.005990\n",
      "  \t137\t\t0.003461\t0.005989\n",
      "  \t138\t\t0.003440\t0.006013\n",
      "  \t139\t\t0.003426\t0.005982\n",
      "  \t140\t\t0.003421\t0.005958\n",
      "  \t141\t\t0.003409\t0.005934\n",
      "  \t142\t\t0.003399\t0.005920\n",
      "  \t143\t\t0.003383\t0.005960\n",
      "  \t144\t\t0.003404\t0.005962\n",
      "  \t145\t\t0.003384\t0.005956\n",
      "  \t146\t\t0.003362\t0.005956\n",
      "  \t147\t\t0.003340\t0.005953\n",
      "  \t148\t\t0.003397\t0.005900\n",
      "  \t149\t\t0.003426\t0.005919\n",
      "  \t150\t\t0.003575\t0.005859\n",
      "  \t151\t\t0.003597\t0.005847\n",
      "  \t152\t\t0.003584\t0.005837\n",
      "  \t153\t\t0.003563\t0.005850\n",
      "  \t154\t\t0.003540\t0.005851\n",
      "  \t155\t\t0.003544\t0.005845\n",
      "  \t156\t\t0.003601\t0.005822\n",
      "  \t157\t\t0.003647\t0.005757\n",
      "  \t158\t\t0.003624\t0.005763\n",
      "  \t159\t\t0.003612\t0.005805\n",
      "  \t160\t\t0.003590\t0.005804\n",
      "  \t161\t\t0.003570\t0.005805\n",
      "  \t162\t\t0.003573\t0.005808\n",
      "  \t163\t\t0.003574\t0.005840\n",
      "  \t164\t\t0.003561\t0.005836\n",
      "  \t165\t\t0.003637\t0.005841\n",
      "  \t166\t\t0.003616\t0.005844\n",
      "  \t167\t\t0.003596\t0.005846\n",
      "  \t168\t\t0.003580\t0.005832\n",
      "  \t169\t\t0.003593\t0.005855\n",
      "  \t170\t\t0.003603\t0.005844\n",
      "  \t171\t\t0.003594\t0.005828\n",
      "  \t172\t\t0.003573\t0.005828\n",
      "  \t173\t\t0.003574\t0.005823\n",
      "  \t174\t\t0.003574\t0.005836\n",
      "  \t175\t\t0.003561\t0.005809\n",
      "  \t176\t\t0.003552\t0.005810\n",
      "  \t177\t\t0.003533\t0.005818\n",
      "  \t178\t\t0.003607\t0.005795\n",
      "  \t179\t\t0.003587\t0.005795\n",
      "  \t180\t\t0.003583\t0.005789\n",
      "  \t181\t\t0.003750\t0.005832\n",
      "  \t182\t\t0.003732\t0.005829\n",
      "  \t183\t\t0.003718\t0.005832\n",
      "  \t184\t\t0.003704\t0.005837\n",
      "  \t185\t\t0.003686\t0.005846\n",
      "  \t186\t\t0.003679\t0.005840\n",
      "  \t187\t\t0.003703\t0.005861\n",
      "  \t188\t\t0.003690\t0.005867\n",
      "  \t189\t\t0.003673\t0.005867\n",
      "  \t190\t\t0.003677\t0.005850\n",
      "  \t191\t\t0.003744\t0.005881\n",
      "  \t192\t\t0.003772\t0.005875\n",
      "  \t193\t\t0.003757\t0.005882\n",
      "  \t194\t\t0.003817\t0.005825\n",
      "  \t195\t\t0.003819\t0.005835\n",
      "  \t196\t\t0.003820\t0.005825\n",
      "  \t197\t\t0.003801\t0.005824\n",
      "  \t198\t\t0.003817\t0.005829\n",
      "  \t199\t\t0.003804\t0.005844\n",
      "  \t200\t\t0.003786\t0.005840\n",
      "  \t201\t\t0.003813\t0.005798\n",
      "  \t202\t\t0.003796\t0.005799\n",
      "  \t203\t\t0.003778\t0.005800\n",
      "  \t204\t\t0.003782\t0.005807\n",
      "  \t205\t\t0.003764\t0.005805\n",
      "  \t206\t\t0.003765\t0.005787\n",
      "  \t207\t\t0.003776\t0.005787\n",
      "  \t208\t\t0.003760\t0.005783\n",
      "  \t209\t\t0.003753\t0.005784\n",
      "  \t210\t\t0.003766\t0.005787\n",
      "  \t211\t\t0.003755\t0.005773\n",
      "  \t212\t\t0.003785\t0.005774\n",
      "  \t213\t\t0.003769\t0.005776\n",
      "  \t214\t\t0.003752\t0.005777\n",
      "  \t215\t\t0.003754\t0.005759\n",
      "  \t216\t\t0.003751\t0.005754\n",
      "  \t217\t\t0.003744\t0.005745\n",
      "  \t218\t\t0.003743\t0.005748\n",
      "  \t219\t\t0.003727\t0.005746\n",
      "  \t220\t\t0.003710\t0.005747\n",
      "  \t221\t\t0.003714\t0.005721\n",
      "  \t222\t\t0.003706\t0.005715\n",
      "  \t223\t\t0.003690\t0.005714\n",
      "  \t224\t\t0.003686\t0.005737\n",
      "  \t225\t\t0.003748\t0.005714\n",
      "  \t226\t\t0.003744\t0.005722\n",
      "  \t227\t\t0.003836\t0.005697\n",
      "  \t228\t\t0.003820\t0.005704\n",
      "  \t229\t\t0.003814\t0.005703\n",
      "  \t230\t\t0.003836\t0.005787\n",
      "  \t231\t\t0.003831\t0.005794\n",
      "  \t232\t\t0.003815\t0.005794\n",
      "  \t233\t\t0.003817\t0.005799\n",
      "  \t234\t\t0.003803\t0.005786\n",
      "  \t235\t\t0.003800\t0.005802\n",
      "  \t236\t\t0.003790\t0.005809\n",
      "  \t237\t\t0.003775\t0.005811\n",
      "  \t238\t\t0.003761\t0.005815\n",
      "  \t239\t\t0.003749\t0.005819\n",
      "  \t240\t\t0.003734\t0.005821\n",
      "  \t241\t\t0.003748\t0.005850\n",
      "  \t242\t\t0.003736\t0.005851\n",
      "  \t243\t\t0.003722\t0.005842\n",
      "  \t244\t\t0.003707\t0.005843\n",
      "  \t245\t\t0.003722\t0.005843\n",
      "  \t246\t\t0.003707\t0.005843\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = y_train.size\n",
    "plt.plot(np.arange(1, m+1), error_train, np.arange(1, m+1), error_test, lw=2)\n",
    "plt.title('Courbe d''apprentissage pour la regression lineaire')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.xlabel('Nombre d''exemples d''apprentissage')\n",
    "plt.ylabel('Erreur')\n",
    "plt.axis([0, 250, 0, 0.09])\n",
    "\n",
    "print('# Training Examples\\tTrain Error\\tCross Validation Error')\n",
    "for i in range(m):\n",
    "    print('  \\t%d\\t\\t%f\\t%f' % (i+1, error_train[i], error_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0LA766bScq4J"
   },
   "source": [
    "**Question:**\n",
    "\n",
    "De quoi souffre ce modele:\n",
    "\n",
    "\n",
    "*   Probléme de variance: overfitting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0038362686930835067"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Lx5nnRZUxB7"
   },
   "source": [
    "**Amelioration du modéle: on cherche les variables corrélées**\n",
    "\n",
    "Visualisation des données par pairs\n",
    "\n",
    "Utilisez la bibliothéque seaborn pour visualiser les données par pairs. Cette visualisation permet de voir les corrélations entre les différentes variables. Vous utiliserez la fonction corr() de pandas pour calculer les coefficient de corrélation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 864
    },
    "colab_type": "code",
    "id": "rXNZbfmkVLij",
    "outputId": "a46fe335-26c3-4128-f7fb-450b49fb0819"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x7f8d5b0f23d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "sn.pairplot(climate_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "mCTVfOSUMCr-",
    "outputId": "8c0b172f-181a-40bb-ac86-52b8cf76c64d"
   },
   "outputs": [],
   "source": [
    "corrMatrix = climate_change.corr()\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-nwH_HpudwmO"
   },
   "source": [
    "**Quelles variables pensez-vous enlever pour rendre le modéle plus performant en tenant compte du heatmap ci-dessus ? Enlevez-les, faites tourner le modéle et dessiner le learning curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GIwZn7iBd-y7"
   },
   "outputs": [],
   "source": [
    "# Simplifier le modéle en enlevant 'CH4', 'CO2', 'CFC-11' et 'CFC-12'\n",
    "climate_change = climate_change.drop(['CH4', 'CO2', 'CFC-11', 'CFC-12'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWl-611hlfdH"
   },
   "source": [
    "**Dessiner à nouveau la matrice de corrélation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "uxc3HEFJlFGD",
    "outputId": "b297853c-dd46-453e-998e-ed90b7d48a79"
   },
   "outputs": [],
   "source": [
    "corrMatrix = climate_change.corr()\n",
    "\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PUnnetCc7Tgr"
   },
   "source": [
    "**Rexecuter à nouveau le modéle et recalcuer theta ainsi que le learning curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oygIJThhfRWc"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(climate_change, y, test_size=0.2, random_state=20)\n",
    "\n",
    "X_train_aug = np.concatenate([np.ones((X_train.shape[0], 1)), X_train], axis=1)\n",
    "X_test_aug = np.concatenate([np.ones((X_test.shape[0], 1)), X_test], axis=1)\n",
    "theta = trainLinearReg(linearRegCostFunction, X_train_aug, y_train, lambda_=0)\n",
    "\n",
    "error_train,error_test = learningCurve(X_train_aug, y_train, X_test_aug, y_test, lambda_=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "x4jntQoff1Zh",
    "outputId": "6e6aac9e-3bea-4a4f-e52a-9938828695f2"
   },
   "outputs": [],
   "source": [
    "m = y_train.size\n",
    "fig= plt.figure(figsize=(15,10))\n",
    "plt.plot(np.arange(1, m+1), error_train, np.arange(1, m+1), error_test, lw=2)\n",
    "plt.title('Courbe d''apprentissage pour la regression lineaire')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.xlabel('Nombre d''exemples d''apprentissage')\n",
    "plt.ylabel('Erreur')\n",
    "plt.axis([0, 250, 0, 0.2])\n",
    "\n",
    "print('# Training Examples\\tTrain Error\\tCross Validation Error')\n",
    "for i in range(m):\n",
    "    print('  \\t%d\\t\\t%f\\t%f' % (i+1, error_train[i], error_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XiPYkS5-iqgc"
   },
   "source": [
    "**Est-ce que le modéle s'est amélioré? Justifier votre reponse**\n",
    "**Est-ce que si nous ajoutons des  données, le modéle va s'améliorer? Justifier votre réponse**\n",
    "\n",
    "**Oui, il y a eu une amélioration.**\n",
    "L'erreur maximale a baissée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80i13CimmH0a"
   },
   "source": [
    "**Formule analytique**\n",
    "\n",
    "Utiliser la formule analytique pour calculer theta et comparer le au theta que vous avez trouvé précédemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MceKdkI20FKA"
   },
   "outputs": [],
   "source": [
    "Z = climate_change.to_numpy()\n",
    "Z = np.concatenate([np.ones((Z.shape[0], 1)), Z], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nJrMVAPN0M_H"
   },
   "outputs": [],
   "source": [
    "theta2 = ((X_train_aug.T.dot(X_train_aug))**(-1)).dot(X_train_aug.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "D8IURllG05Gf",
    "outputId": "9a895211-6a75-47ee-e563-884c210446ad"
   },
   "outputs": [],
   "source": [
    "theta2, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5vmZytKt4wxS"
   },
   "source": [
    "**Exercice**\n",
    "\n",
    "Creer un modéle de regression linéaire en utilisant scikit-learn et faites de la prediction avec ce modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(np.array(X_test.iloc[95]).reshape(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copie de LinearRegression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
